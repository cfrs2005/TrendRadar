#!/usr/bin/env python3
"""
æ–°é—»å†…å®¹å¢å¼ºå¤„ç†å™¨
å®ç° Hacker News æ ‡é¢˜æ±‰åŒ–å’Œå†…å®¹å»é‡åŠŸèƒ½
"""

import re
import hashlib
import os
from typing import Dict, List, Optional, Tuple
from datetime import datetime


class NewsEnhancer:
    """æ–°é—»å†…å®¹å¢å¼ºå™¨"""
    
    def __init__(self):
        self.clude_token = os.environ.get("CLAUDE_CODE_OAUTH_TOKEN")
        self.enable_ai = bool(self.clude_token)
        
        # ç®€å•çš„è‹±æ–‡åˆ°ä¸­æ–‡ç¿»è¯‘è¯å…¸ï¼ˆç”¨äºå¸¸è§çš„ Hacker News æ ‡é¢˜è¯æ±‡ï¼‰
        self.translation_dict = {
            # æŠ€æœ¯æœ¯è¯­
            "AI": "äººå·¥æ™ºèƒ½", "API": "æ¥å£", "algorithm": "ç®—æ³•", "artificial": "äººå·¥", 
            "blockchain": "åŒºå—é“¾", "bug": "æ¼æ´", "code": "ä»£ç ", "coding": "ç¼–ç¨‹",
            "cybersecurity": "ç½‘ç»œå®‰å…¨", "data": "æ•°æ®", "database": "æ•°æ®åº“",
            "debug": "è°ƒè¯•", "development": "å¼€å‘", "devops": "è¿ç»´å¼€å‘",
            "encryption": "åŠ å¯†", "framework": "æ¡†æ¶", "git": "Git", "github": "GitHub",
            "hacker": "é»‘å®¢", "hardware": "ç¡¬ä»¶", "internet": "äº’è”ç½‘", "javascript": "JavaScript",
            "linux": "Linux", "machine": "æœºå™¨", "malware": "æ¶æ„è½¯ä»¶", "network": "ç½‘ç»œ",
            "open source": "å¼€æº", "programming": "ç¼–ç¨‹", "python": "Python", "quantum": "é‡å­",
            "repository": "ä»“åº“", "security": "å®‰å…¨", "server": "æœåŠ¡å™¨", "software": "è½¯ä»¶",
            "system": "ç³»ç»Ÿ", "technology": "æŠ€æœ¯", "testing": "æµ‹è¯•", "tool": "å·¥å…·",
            "update": "æ›´æ–°", "version": "ç‰ˆæœ¬", "vulnerability": "æ¼æ´", "web": "ç½‘ç»œ",
            "website": "ç½‘ç«™", "windows": "Windows", "app": "åº”ç”¨", "application": "åº”ç”¨ç¨‹åº",
            
            # åŠ¨ä½œè¯
            "released": "å‘å¸ƒ", "launched": "æ¨å‡º", "announced": "å®£å¸ƒ", "updated": "æ›´æ–°",
            "fixed": "ä¿®å¤", "improved": "æ”¹è¿›", "added": "æ·»åŠ ", "removed": "ç§»é™¤",
            "changed": "æ”¹å˜", "created": "åˆ›å»º", "developed": "å¼€å‘", "designed": "è®¾è®¡",
            "built": "æ„å»º", "implemented": "å®ç°", "discovered": "å‘ç°", "found": "å‘ç°",
            "reported": "æŠ¥å‘Š", "revealed": "æ­ç¤º", "showed": "æ˜¾ç¤º", "tested": "æµ‹è¯•",
            "analyzed": "åˆ†æ", "compared": "æ¯”è¾ƒ", "reviewed": "å®¡æŸ¥", "evaluated": "è¯„ä¼°",
            
            # æè¿°è¯
            "new": "æ–°", "latest": "æœ€æ–°", "popular": "çƒ­é—¨", "trending": "è¶‹åŠ¿", "viral": "ç—…æ¯’å¼",
            "free": "å…è´¹", "open": "å¼€æ”¾", "closed": "å…³é—­", "public": "å…¬å…±", "private": "ç§æœ‰",
            "secure": "å®‰å…¨", "insecure": "ä¸å®‰å…¨", "fast": "å¿«é€Ÿ", "slow": "æ…¢é€Ÿ",
            "easy": "ç®€å•", "complex": "å¤æ‚", "powerful": "å¼ºå¤§", "useful": "æœ‰ç”¨",
            "better": "æ›´å¥½", "worse": "æ›´å·®", "best": "æœ€ä½³", "worst": "æœ€å·®",
            "big": "å¤§", "small": "å°", "large": "å¤§å‹", "tiny": "å¾®å°", "huge": "å·¨å¤§",
            
            # æ•°å­—å•ä½
            "million": "ç™¾ä¸‡", "billion": "åäº¿", "trillion": "ä¸‡äº¿", "k": "åƒ", "m": "ç™¾ä¸‡",
            
            # å…¬å¸åç§°
            "google": "è°·æ­Œ", "microsoft": "å¾®è½¯", "apple": "è‹¹æœ", "amazon": "äºšé©¬é€Š",
            "facebook": "Facebook", "meta": "Meta", "twitter": "Twitter", "tesla": "ç‰¹æ–¯æ‹‰",
            "netflix": "Netflix", "adobe": "Adobe", "oracle": "ç”²éª¨æ–‡", "samsung": "ä¸‰æ˜Ÿ",
            "intel": "è‹±ç‰¹å°”", "nvidia": "è‹±ä¼Ÿè¾¾", "amd": "AMD", "ibm": "IBM",
            
            # å…¶ä»–å¸¸è§è¯
            "apple": "è‹¹æœ", "iphone": "iPhone", "android": "å®‰å“", "phone": "æ‰‹æœº",
            "computer": "ç”µè„‘", "laptop": "ç¬”è®°æœ¬ç”µè„‘", "desktop": "å°å¼æœº",
            "browser": "æµè§ˆå™¨", "chrome": "Chrome", "firefox": "Firefox", "safari": "Safari",
            "email": "é‚®ä»¶", "message": "æ¶ˆæ¯", "chat": "èŠå¤©", "social": "ç¤¾äº¤",
            "media": "åª’ä½“", "video": "è§†é¢‘", "audio": "éŸ³é¢‘", "image": "å›¾ç‰‡",
            "photo": "ç…§ç‰‡", "file": "æ–‡ä»¶", "document": "æ–‡æ¡£", "text": "æ–‡æœ¬",
            "game": "æ¸¸æˆ", "play": "ç©", "player": "æ’­æ”¾å™¨", "music": "éŸ³ä¹",
            "movie": "ç”µå½±", "book": "ä¹¦", "news": "æ–°é—»", "article": "æ–‡ç« ",
            "blog": "åšå®¢", "post": "å¸–å­", "comment": "è¯„è®º", "reply": "å›å¤",
            "user": "ç”¨æˆ·", "account": "è´¦æˆ·", "login": "ç™»å½•", "password": "å¯†ç ",
            "name": "åç§°", "title": "æ ‡é¢˜", "content": "å†…å®¹", "page": "é¡µé¢",
            "site": "ç½‘ç«™", "link": "é“¾æ¥", "url": "ç½‘å€", "address": "åœ°å€",
            "location": "ä½ç½®", "place": "åœ°æ–¹", "country": "å›½å®¶", "city": "åŸå¸‚",
            "time": "æ—¶é—´", "date": "æ—¥æœŸ", "year": "å¹´", "month": "æœˆ", "day": "å¤©",
            "hour": "å°æ—¶", "minute": "åˆ†é’Ÿ", "second": "ç§’", "today": "ä»Šå¤©", "yesterday": "æ˜¨å¤©",
            "tomorrow": "æ˜å¤©", "now": "ç°åœ¨", "future": "æœªæ¥", "past": "è¿‡å»"
        }
    
    def translate_hackernews_title(self, title: str, source_id: str) -> str:
        """
        ç¿»è¯‘ Hacker News æ ‡é¢˜
        """
        if source_id != "hackernews":
            return title
        
        if not self.enable_ai:
            # å¦‚æœæ²¡æœ‰å¯ç”¨AIï¼Œä½¿ç”¨ç®€å•çš„è¯å…¸ç¿»è¯‘
            return self._simple_translate(title)
        
        # å¦‚æœå¯ç”¨äº†AIï¼Œå¯ä»¥åœ¨è¿™é‡Œè°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œç¿»è¯‘
        # ç›®å‰æš‚æ—¶ä½¿ç”¨ç®€å•ç¿»è¯‘
        return self._simple_translate(title)
    
    def _simple_translate(self, title: str) -> str:
        """
        ç®€å•çš„è¯å…¸ç¿»è¯‘
        """
        # å°†æ ‡é¢˜è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
        title_lower = title.lower()
        
        # æ›¿æ¢è¯å…¸ä¸­çš„è¯æ±‡
        translated_title = title
        for en_word, zh_word in self.translation_dict.items():
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œå•è¯è¾¹ç•ŒåŒ¹é…
            pattern = r'\b' + re.escape(en_word) + r'\b'
            translated_title = re.sub(pattern, zh_word, translated_title, flags=re.IGNORECASE)
        
        return translated_title
    
    def generate_content_hash(self, title: str, source_id: str) -> str:
        """
        ç”Ÿæˆå†…å®¹å“ˆå¸Œå€¼ç”¨äºå»é‡
        """
        # æ ‡å‡†åŒ–æ ‡é¢˜ï¼šå»é™¤æ ‡ç‚¹ç¬¦å·ã€è½¬å°å†™
        normalized_title = re.sub(r'[^\w\s]', '', title.lower())
        
        # ç”Ÿæˆå“ˆå¸Œ
        content = f"{source_id}:{normalized_title}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def check_duplicate_content(self, all_results: Dict, title_info: Optional[Dict] = None) -> Tuple[Dict, Dict]:
        """
        æ£€æŸ¥å¹¶å»é™¤é‡å¤å†…å®¹
        """
        seen_hashes = {}
        deduped_results = {}
        removed_items = {}
        total_removed = 0
        
        # å¦‚æœæœ‰å†å²title_infoï¼Œå…ˆæ·»åŠ åˆ°seen_hashesä¸­
        if title_info:
            for source_id, titles in title_info.items():
                for title in titles:
                    content_hash = self.generate_content_hash(title, source_id)
                    # æ ‡è®°å†å²å†…å®¹ä¸ºå·²æ¨é€
                    seen_hashes[content_hash] = "historical"
        
        # å¤„ç†å½“å‰ç»“æœ
        for source_id, titles_data in all_results.items():
            deduped_results[source_id] = {}
            
            for title, title_data in titles_data.items():
                content_hash = self.generate_content_hash(title, source_id)
                
                if content_hash in seen_hashes:
                    # å‘ç°é‡å¤å†…å®¹
                    if source_id not in removed_items:
                        removed_items[source_id] = {}
                    removed_items[source_id][title] = {
                        "title_data": title_data,
                        "reason": seen_hashes[content_hash]  # "historical" æˆ– "current"
                    }
                    total_removed += 1
                else:
                    # ä¿ç•™ä¸é‡å¤çš„å†…å®¹
                    deduped_results[source_id][title] = title_data
                    seen_hashes[content_hash] = "current"
        
        print(f"ğŸ¤– æ™ºèƒ½å»é‡: åŸå§‹å†…å®¹ {sum(len(titles) for titles in all_results.values())} æ¡ â†’ å»é‡å {sum(len(titles) for titles in deduped_results.values())} æ¡ (å»é™¤ {total_removed} æ¡é‡å¤)")
        
        if removed_items:
            print(f"ğŸ“‹ å»é‡è¯¦æƒ…: å„å¹³å°å»é™¤é‡å¤å†…å®¹æ•°é‡")
            for source_id, items in removed_items.items():
                if items:
                    print(f"  - {source_id}: å»é™¤ {len(items)} æ¡")
        
        return deduped_results, removed_items
    
    def enhance_news_data(self, all_results: Dict, title_info: Optional[Dict] = None) -> Tuple[Dict, Dict]:
        """
        å¢å¼ºæ–°é—»æ•°æ®ï¼šç¿»è¯‘ Hacker News æ ‡é¢˜å¹¶å»é‡
        """
        print(f"ğŸš€ å¼€å§‹å†…å®¹å¢å¼ºå¤„ç†...")
        
        # ç¬¬ä¸€æ­¥ï¼šå»é‡
        deduped_results, removed_items = self.check_duplicate_content(all_results, title_info)
        
        # ç¬¬äºŒæ­¥ï¼šç¿»è¯‘ Hacker News æ ‡é¢˜
        enhanced_results = {}
        translated_count = 0
        
        for source_id, titles_data in deduped_results.items():
            enhanced_results[source_id] = {}
            
            for title, title_data in titles_data.items():
                translated_title = self.translate_hackernews_title(title, source_id)
                
                # å¦‚æœæ ‡é¢˜è¢«ç¿»è¯‘äº†ï¼Œæ›´æ–°æ ‡é¢˜
                if translated_title != title:
                    # æ›´æ–°æ ‡é¢˜æ•°æ®
                    enhanced_title_data = title_data.copy()
                    enhanced_title_data["original_title"] = title  # ä¿ç•™åŸå§‹æ ‡é¢˜
                    enhanced_results[source_id][translated_title] = enhanced_title_data
                    translated_count += 1
                else:
                    enhanced_results[source_id][title] = title_data
        
        if translated_count > 0:
            print(f"ğŸˆ¯ï¸ Hacker News æ ‡é¢˜ç¿»è¯‘: ç¿»è¯‘äº† {translated_count} ä¸ªæ ‡é¢˜")
        
        print(f"âœ… å†…å®¹å¢å¼ºå®Œæˆ")
        
        return enhanced_results, removed_items


# å…¨å±€å®ä¾‹
_news_enhancer = NewsEnhancer()


def enhance_news_data(all_results: Dict, title_info: Optional[Dict] = None) -> Tuple[Dict, Dict]:
    """
    å…¨å±€å‡½æ•°ï¼šå¢å¼ºæ–°é—»æ•°æ®
    """
    return _news_enhancer.enhance_news_data(all_results, title_info)


def translate_hackernews_title(title: str, source_id: str) -> str:
    """
    å…¨å±€å‡½æ•°ï¼šç¿»è¯‘ Hacker News æ ‡é¢˜
    """
    return _news_enhancer.translate_hackernews_title(title, source_id)


def check_duplicate_content(all_results: Dict, title_info: Optional[Dict] = None) -> Tuple[Dict, Dict]:
    """
    å…¨å±€å‡½æ•°ï¼šæ£€æŸ¥é‡å¤å†…å®¹
    """
    return _news_enhancer.check_duplicate_content(all_results, title_info)