#!/usr/bin/env python3
"""
æ–°é—»å†…å®¹å¢å¼ºåŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import os
import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from news_enhancer import (
    NewsEnhancer, 
    enhance_news_data, 
    translate_hackernews_title,
    check_duplicate_content
)


def test_hackernews_translation():
    """æµ‹è¯• Hacker News æ ‡é¢˜ç¿»è¯‘åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯• Hacker News æ ‡é¢˜ç¿»è¯‘åŠŸèƒ½")
    
    enhancer = NewsEnhancer()
    
    test_cases = [
        ("AI agents find $4.6M in blockchain smart contract exploits", "hackernews"),
        ("OpenAI releases new GPT-4 model with improved capabilities", "hackernews"), 
        ("Google announces new quantum computing breakthrough", "hackernews"),
        ("Microsoft Windows 11 gets new AI-powered features", "hackernews"),
        ("Apple reveals new iPhone with advanced camera system", "hackernews"),
        ("This is a regular Chinese title from other source", "weibo"),
    ]
    
    for title, source_id in test_cases:
        translated = enhancer.translate_hackernews_title(title, source_id)
        print(f"  ğŸ“° [{source_id}] {title}")
        if translated != title:
            print(f"     â¡ï¸ {translated}")
        else:
            print(f"     âœ… (æ— éœ€ç¿»è¯‘)")
        print()


def test_duplicate_detection():
    """æµ‹è¯•é‡å¤å†…å®¹æ£€æµ‹åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•é‡å¤å†…å®¹æ£€æµ‹åŠŸèƒ½")
    
    enhancer = NewsEnhancer()
    
    # æ¨¡æ‹Ÿæ–°é—»æ•°æ®
    test_data = {
        "hackernews": {
            "AI agents find $4.6M in blockchain smart contract exploits": {
                "ranks": [1],
                "url": "https://news.ycombinator.com/item?id=123",
                "mobileUrl": "https://news.ycombinator.com/item?id=123"
            },
            "OpenAI releases new GPT-4 model": {
                "ranks": [2],
                "url": "https://news.ycombinator.com/item?id=124", 
                "mobileUrl": "https://news.ycombinator.com/item?id=124"
            },
            "AI agents find $4.6M in blockchain exploits": {  # ç±»ä¼¼é‡å¤å†…å®¹
                "ranks": [3],
                "url": "https://news.ycombinator.com/item?id=125",
                "mobileUrl": "https://news.ycombinator.com/item?id=125"
            }
        },
        "zhihu": {
            "ç½‘è­¦ç ´è·"AIæ¢è„¸"ä¾µå…¥è®¡ç®—æœºæ¡ˆ": {
                "ranks": [1],
                "url": "https://www.zhihu.com/question/123",
                "mobileUrl": "https://www.zhihu.com/question/123"
            }
        },
        "weibo": {
            "ç½‘è­¦ç ´è·AIæ¢è„¸éæ³•ä¾µå…¥ç³»ç»Ÿæ¡ˆ": {  # é‡å¤å†…å®¹
                "ranks": [2],
                "url": "https://weibo.com/123",
                "mobileUrl": "https://weibo.com/123"
            },
            "ç½‘è­¦ç ´è·"AIæ¢è„¸"ä¾µå…¥è®¡ç®—æœºæ¡ˆ": {  # å®Œå…¨é‡å¤
                "ranks": [3],
                "url": "https://weibo.com/124", 
                "mobileUrl": "https://weibo.com/124"
            }
        }
    }
    
    # æ¨¡æ‹Ÿå†å²æ•°æ®
    historical_data = {
        "bilibili-hot-search": {
            "ç½‘è­¦ç ´è·AIæ¢è„¸éæ³•ä¾µå…¥ç³»ç»Ÿæ¡ˆ": {  # å†å²é‡å¤å†…å®¹
                "ranks": [1],
                "url": "https://bilibili.com/123",
                "mobileUrl": "https://bilibili.com/123"
            }
        }
    }
    
    print("  ğŸ“Š åŸå§‹æ•°æ®ç»Ÿè®¡:")
    for source_id, titles_data in test_data.items():
        print(f"    - {source_id}: {len(titles_data)} æ¡")
    
    print(f"\n  ğŸ“ˆ å†å²æ•°æ®ç»Ÿè®¡:")
    for source_id, titles_data in historical_data.items():
        print(f"    - {source_id}: {len(titles_data)} æ¡")
    
    # æµ‹è¯•å»é‡åŠŸèƒ½
    deduped_data, removed_items = enhancer.check_duplicate_content(test_data, historical_data)
    
    print(f"\n  ğŸ§¹ å»é‡ç»“æœ:")
    for source_id, titles_data in deduped_data.items():
        print(f"    - {source_id}: {len(titles_data)} æ¡ (ä¿ç•™)")
    
    print(f"\n  ğŸ—‘ï¸  å»é™¤çš„å†…å®¹:")
    for source_id, items in removed_items.items():
        print(f"    - {source_id}: {len(items)} æ¡")
        for title, item_info in items.items():
            reason = item_info["reason"]
            print(f"      â€¢ {title[:50]}... (åŸå› : {reason})")
    
    return deduped_data, removed_items


def test_complete_enhancement():
    """æµ‹è¯•å®Œæ•´çš„å†…å®¹å¢å¼ºåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å®Œæ•´çš„å†…å®¹å¢å¼ºåŠŸèƒ½")
    
    # æµ‹è¯•æ•°æ®
    test_results = {
        "hackernews": {
            "AI agents find $4.6M in blockchain smart contract exploits": {
                "ranks": [1],
                "url": "https://news.ycombinator.com/item?id=123",
                "mobileUrl": "https://news.ycombinator.com/item?id=123"
            },
            "Google announces new quantum computing breakthrough": {
                "ranks": [2], 
                "url": "https://news.ycombinator.com/item?id=124",
                "mobileUrl": "https://news.ycombinator.com/item?id=124"
            }
        },
        "zhihu": {
            "ç½‘è­¦ç ´è·"AIæ¢è„¸"ä¾µå…¥è®¡ç®—æœºæ¡ˆ": {
                "ranks": [1],
                "url": "https://www.zhihu.com/question/123",
                "mobileUrl": "https://www.zhihu.com/question/123"
            }
        }
    }
    
    # æ¨¡æ‹Ÿå†å²æ•°æ®
    title_info = {
        "weibo": {
            "ç½‘è­¦ç ´è·AIæ¢è„¸éæ³•ä¾µå…¥ç³»ç»Ÿæ¡ˆ": {
                "first_time": "10æ—¶54åˆ†",
                "last_time": "12æ—¶27åˆ†", 
                "count": 3
            }
        }
    }
    
    print("  ğŸ“Š å¢å¼ºå‰æ•°æ®:")
    for source_id, titles_data in test_results.items():
        print(f"    - {source_id}: {len(titles_data)} æ¡")
    
    # æ‰§è¡Œå†…å®¹å¢å¼º
    enhanced_results, removed_items = enhance_news_data(test_results, title_info)
    
    print(f"\n  ğŸš€ å¢å¼ºåæ•°æ®:")
    for source_id, titles_data in enhanced_results.items():
        print(f"    - {source_id}: {len(titles_data)} æ¡")
        for title in titles_data.keys():
            print(f"      â€¢ {title}")
            # æ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹æ ‡é¢˜å­—æ®µ
            if "original_title" in titles_data[title]:
                print(f"        (åŸæ ‡é¢˜: {titles_data[title]['original_title']})")
    
    print(f"\n  ğŸ—‘ï¸  å»é™¤å†…å®¹:")
    for source_id, items in removed_items.items():
        print(f"    - {source_id}: {len(items)} æ¡")
    
    return enhanced_results, removed_items


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æ–°é—»å†…å®¹å¢å¼ºåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    claude_token = os.environ.get("CLAUDE_CODE_OAUTH_TOKEN")
    if claude_token:
        print(f"âœ… æ£€æµ‹åˆ° Claude Token (é•¿åº¦: {len(claude_token)})")
        print("   å°†å¯ç”¨ AI å¢å¼ºåŠŸèƒ½")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ° Claude Token")
        print("   å°†ä½¿ç”¨ç®€å•çš„è¯å…¸ç¿»è¯‘åŠŸèƒ½")
    
    print(f"\nâ° æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print("\n" + "=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    try:
        test_hackernews_translation()
        print("\n" + "-" * 50)
        
        test_duplicate_detection()
        print("\n" + "-" * 50)
        
        test_complete_enhancement()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)