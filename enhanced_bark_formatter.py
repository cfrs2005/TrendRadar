#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¢å¼ºçš„Barkæ¶ˆæ¯æ ¼å¼åŒ–å™¨
Enhanced Bark message formatter with improved markdown and table support
"""

from datetime import datetime
from typing import Dict, List, Any, Optional
from enhanced_duplicate_detector import EnhancedDuplicateDetector


class EnhancedBarkFormatter:
    """å¢å¼ºçš„Barkæ¶ˆæ¯æ ¼å¼åŒ–å™¨"""
    
    def __init__(self, enable_duplicate_detection: bool = True):
        self.enable_duplicate_detection = enable_duplicate_detection
        if enable_duplicate_detection:
            self.duplicate_detector = EnhancedDuplicateDetector(enable_similarity_check=True)
        else:
            self.duplicate_detector = None
    
    def format_enhanced_message(self, report_data: Dict[str, Any], now: datetime, 
                             update_info: Optional[Dict[str, str]] = None) -> List[str]:
        """æ ¼å¼åŒ–å¢å¼ºçš„Barkæ¶ˆæ¯"""
        
        # å»é‡å¤„ç†
        if self.enable_duplicate_detection and self.duplicate_detector:
            filtered_report_data = self._remove_duplicates(report_data)
        else:
            filtered_report_data = report_data
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        message_content = self._build_message_content(filtered_report_data, now, update_info)
        
        # æŒ‰Barkå¤§å°é™åˆ¶åˆ†æ‰¹
        batches = self._create_batches_for_bark(message_content)
        
        return batches
    
    def _remove_duplicates(self, report_data: Dict[str, Any]) -> Dict[str, Any]:
        """å»é™¤é‡å¤å†…å®¹"""
        if not report_data.get("new_titles"):
            return report_data
        
        filtered_report_data = report_data.copy()
        filtered_new_titles = []
        
        for source_data in report_data["new_titles"]:
            filtered_titles = []
            
            for title_data in source_data["titles"]:
                title = title_data.get("title", "")
                platform = source_data["source_name"]
                
                # æ£€æŸ¥é‡å¤
                is_unique = self.duplicate_detector.add_content(title, platform, title_data)
                
                if is_unique:
                    filtered_titles.append(title_data)
            
            if filtered_titles:  # åªä¿ç•™æœ‰å†…å®¹çš„å¹³å°
                filtered_source_data = source_data.copy()
                filtered_source_data["titles"] = filtered_titles
                filtered_new_titles.append(filtered_source_data)
        
        filtered_report_data["new_titles"] = filtered_new_titles
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        if filtered_report_data.get("stats"):
            # å¯ä»¥åœ¨è¿™é‡Œæ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼Œç¡®ä¿åªåŒ…å«å»é‡åçš„å†…å®¹
            pass
        
        return filtered_report_data
    
    def _build_message_content(self, report_data: Dict[str, Any], now: datetime, 
                              update_info: Optional[Dict[str, str]] = None) -> str:
        """æ„å»ºæ¶ˆæ¯å†…å®¹"""
        content_parts = []
        
        # æ·»åŠ å¤´éƒ¨ä¿¡æ¯
        content_parts.append(self._format_header(report_data, now))
        
        # æ·»åŠ å»é‡æ‘˜è¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enable_duplicate_detection and self.duplicate_detector:
            duplicate_summary = self.duplicate_detector.get_duplicate_summary()
            content_parts.append(duplicate_summary)
            content_parts.append("---\n")
        
        # æ·»åŠ çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡è¡¨æ ¼
        if report_data.get("stats"):
            stats_table = self._format_stats_table(report_data["stats"])
            content_parts.append(stats_table)
            content_parts.append("")
        
        # æ·»åŠ æ–°å¢çƒ­ç‚¹æ–°é—»
        if report_data.get("new_titles"):
            news_section = self._format_news_section(report_data["new_titles"])
            content_parts.append(news_section)
        
        # æ·»åŠ å¤±è´¥å¹³å°ä¿¡æ¯
        if report_data.get("failed_ids"):
            failed_section = self._format_failed_section(report_data["failed_ids"])
            content_parts.append(failed_section)
        
        # æ·»åŠ é‡å¤å†…å®¹è¯¦æƒ…ï¼ˆå¦‚æœæœ‰ä¸”å¯ç”¨ï¼‰
        if self.enable_duplicate_detection and self.duplicate_detector:
            duplicate_details = self.duplicate_detector.get_duplicate_details()
            if "æœªå‘ç°é‡å¤å†…å®¹" not in duplicate_details:
                content_parts.append("---\n")
                content_parts.append(duplicate_details)
        
        # æ·»åŠ åº•éƒ¨ä¿¡æ¯
        content_parts.append(self._format_footer(now, update_info))
        
        return "\n\n".join(content_parts)
    
    def _format_header(self, report_data: Dict[str, Any], now: datetime) -> str:
        """æ ¼å¼åŒ–å¤´éƒ¨ä¿¡æ¯"""
        total_count = sum(len(source_data.get("titles", [])) 
                         for source_data in report_data.get("new_titles", []))
        
        header_parts = [
            "# ğŸ“° TrendRadar çƒ­ç‚¹é›·è¾¾",
            f"**æ¨é€æ—¶é—´:** {now.strftime('%Y-%m-%d %H:%M:%S')}",
            f"**æ–°é—»æ€»æ•°:** {total_count} æ¡"
        ]
        
        return "\n".join(header_parts)
    
    def _format_stats_table(self, stats: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–ç»Ÿè®¡è¡¨æ ¼"""
        if not stats:
            return ""
        
        # æ„å»ºMarkdownè¡¨æ ¼
        table_parts = [
            "## ğŸ“Š çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡",
            "",
            "| æ’å | çƒ­ç‚¹è¯æ±‡ | å‡ºç°æ¬¡æ•° | å¹³å°åˆ†å¸ƒ |",
            "|------|----------|----------|----------|"
        ]
        
        for i, stat in enumerate(stats[:10], 1):  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ª
            word = stat.get("word", "")
            count = stat.get("count", 0)
            platforms = " ".join(stat.get("platforms", []))
            
            # æˆªæ–­è¿‡é•¿çš„å†…å®¹
            platforms = platforms[:20] + "..." if len(platforms) > 20 else platforms
            
            table_parts.append(f"| {i} | **{word}** | {count} | {platforms} |")
        
        return "\n".join(table_parts)
    
    def _format_news_section(self, new_titles: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æ–°é—»æ¿å—"""
        if not new_titles:
            return ""
        
        news_parts = ["## ğŸ†• æ–°å¢çƒ­ç‚¹æ–°é—»"]
        
        for source_data in new_titles:
            source_name = source_data.get("source_name", "æœªçŸ¥å¹³å°")
            titles = source_data.get("titles", [])
            
            if not titles:
                continue
            
            news_parts.append("")
            news_parts.append(f"### ğŸ“± {source_name} ({len(titles)} æ¡)")
            
            # æ„å»ºè¯¥å¹³å°çš„è¡¨æ ¼
            news_parts.append("")
            news_parts.append("| åºå· | æ–°é—»æ ‡é¢˜ | çƒ­åº¦ | æ—¶é—´èŒƒå›´ |")
            news_parts.append("|------|----------|------|----------|")
            
            for i, title_data in enumerate(titles[:15], 1):  # é™åˆ¶æ¯ä¸ªå¹³å°æœ€å¤š15æ¡
                title = title_data.get("title", "")
                ranks = title_data.get("ranks", [])
                first_time = title_data.get("first_time", "")
                last_time = title_data.get("last_time", "")
                
                # æˆªæ–­è¿‡é•¿çš„æ ‡é¢˜
                title = title[:40] + "..." if len(title) > 40 else title
                if not title:
                    title = "æ ‡é¢˜è·å–å¤±è´¥"
                
                # å¤„ç†çƒ­åº¦ä¿¡æ¯
                heat_info = ""
                if ranks:
                    try:
                        heat_info = f"#{min(ranks)}"
                    except (ValueError, TypeError):
                        heat_info = "N/A"
                else:
                    heat_info = "N/A"
                
                # å¤„ç†æ—¶é—´ä¿¡æ¯
                time_range = ""
                if first_time and last_time and first_time != last_time:
                    time_range = f"{first_time} ~ {last_time}"
                elif first_time:
                    time_range = first_time
                else:
                    time_range = "æœªçŸ¥æ—¶é—´"
                
                news_parts.append(f"| {i} | {title} | {heat_info} | {time_range} |")
            
            if len(titles) > 15:
                news_parts.append(f"| ... | **è¿˜æœ‰ {len(titles) - 15} æ¡** | ... | ... |")
        
        return "\n".join(news_parts)
    
    def _format_failed_section(self, failed_ids: List[str]) -> str:
        """æ ¼å¼åŒ–å¤±è´¥æ¿å—"""
        if not failed_ids:
            return ""
        
        failed_parts = [
            "## âš ï¸ æ•°æ®è·å–å¼‚å¸¸",
            "",
            "ä»¥ä¸‹å¹³å°æœ¬æ¬¡æ•°æ®è·å–å¤±è´¥ï¼š"
        ]
        
        for i, platform_id in enumerate(failed_ids, 1):
            failed_parts.append(f"{i}. `{platform_id}`")
        
        return "\n".join(failed_parts)
    
    def _format_footer(self, now: datetime, update_info: Optional[Dict[str, str]] = None) -> str:
        """æ ¼å¼åŒ–åº•éƒ¨ä¿¡æ¯"""
        footer_parts = [
            "---",
            f"ğŸ“¡ **TrendRadaræ™ºèƒ½çƒ­ç‚¹æ¨é€** | {now.strftime('%Y-%m-%d %H:%M:%S')}"
        ]
        
        if update_info:
            footer_parts.append(
                f"ğŸ”„ å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}** (å½“å‰: {update_info['current_version']})"
            )
        
        return "\n".join(footer_parts)
    
    def _create_batches_for_bark(self, content: str, max_size: int = 3500) -> List[str]:
        """ä¸ºBarkåˆ›å»ºæ¶ˆæ¯æ‰¹æ¬¡"""
        if len(content.encode('utf-8')) <= max_size:
            return [content]
        
        batches = []
        lines = content.split('\n')
        current_batch = ""
        batch_num = 1
        
        for line in lines:
            # å°è¯•æ·»åŠ å½“å‰è¡Œåˆ°æ‰¹æ¬¡
            test_batch = current_batch + ("\n" if current_batch else "") + line
            
            if len(test_batch.encode('utf-8')) <= max_size:
                current_batch = test_batch
            else:
                # å¦‚æœå½“å‰æ‰¹æ¬¡ä¸ä¸ºç©ºï¼Œå…ˆä¿å­˜
                if current_batch:
                    batches.append(self._add_batch_header(current_batch, batch_num))
                    batch_num += 1
                
                # å¦‚æœå•è¡Œå°±è¶…è¿‡é™åˆ¶ï¼Œéœ€è¦æˆªæ–­
                if len(line.encode('utf-8')) > max_size - 100:  # é¢„ç•™å¤´éƒ¨ç©ºé—´
                    truncated_line = line[:max_size//4] + "...[å†…å®¹è¿‡é•¿å·²æˆªæ–­]"
                    batches.append(self._add_batch_header(truncated_line, batch_num))
                    batch_num += 1
                    current_batch = ""
                else:
                    current_batch = line
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if current_batch:
            batches.append(self._add_batch_header(current_batch, batch_num))
        
        return batches
    
    def _add_batch_header(self, content: str, batch_num: int) -> str:
        """æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨"""
        header = f"ğŸ“¦ **[ç¬¬ {batch_num} éƒ¨åˆ†]**"
        return f"{header}\n\n{content}" if content else header
    
    def get_duplicate_stats(self) -> Optional[Dict[str, Any]]:
        """è·å–å»é‡ç»Ÿè®¡ä¿¡æ¯"""
        if self.duplicate_detector:
            return self.duplicate_detector.get_stats_dict()
        return None
    
    def reset_duplicate_stats(self):
        """é‡ç½®å»é‡ç»Ÿè®¡"""
        if self.duplicate_detector:
            self.duplicate_detector.reset_stats()